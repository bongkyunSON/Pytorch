{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bongkyunSON/Pytorch/blob/main/Pytorch_linear_layer_221221.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4nKXIHfVzNO"
      },
      "source": [
        "# Linear Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1sAkGUpsVzNS"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6PuwZhaVzNT"
      },
      "source": [
        "## Raw Linear Layer\n",
        "\n",
        "$$\\begin{gathered}\n",
        "y=x\\cdot{W}+b, \\\\\n",
        "\\text{where }x\\in\\mathbb{R}^{N\\times{n}}\\text{, }y\\in\\mathbb{R}^{N\\times{m}}. \\\\\n",
        "\\\\\n",
        "\\text{Thus, }W\\in\\mathbb{R}^{n\\times{m}}\\text{ and }b\\in\\mathbb{R}^m.\n",
        "\\end{gathered}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yVDum-siVzNU"
      },
      "outputs": [],
      "source": [
        "W = torch.FloatTensor([[1, 2],\n",
        "                       [3, 4],\n",
        "                       [5, 6]])\n",
        "b = torch.FloatTensor([2, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FpgHsotVzNV",
        "outputId": "dd7bf0ca-76f1-44c6-9eba-7fd0e5dfabaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 2])\n",
            "torch.Size([2])\n"
          ]
        }
      ],
      "source": [
        "print(W.size())\n",
        "print(b.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pT6_5izEVzNV"
      },
      "outputs": [],
      "source": [
        "def linear(x, W, b):\n",
        "    y = torch.matmul(x, W) + b\n",
        "    \n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUSomH7cVzNW",
        "outputId": "07598be3-4b52-4bff-ba38-2c6f1ad0b533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3])\n"
          ]
        }
      ],
      "source": [
        "x = torch.FloatTensor([[1, 1, 1],\n",
        "                       [2, 2, 2],\n",
        "                       [3, 3, 3],\n",
        "                       [4, 4, 4]])\n",
        "\n",
        "print(x.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NCwmQsvzVzNW"
      },
      "outputs": [],
      "source": [
        "y = linear(x, W, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzFFYwsKVzNX",
        "outputId": "189f882d-2f87-41c2-8263-cf29dd981494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 2])\n"
          ]
        }
      ],
      "source": [
        "print(y.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XRw9OZPVzNX"
      },
      "source": [
        "## nn.Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SePcyEkzVzNX"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BN4pln9NVzNY"
      },
      "outputs": [],
      "source": [
        "class MyLinear(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim=3, output_dim=2):\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.W = torch.FloatTensor(input_dim, output_dim)\n",
        "        self.b = torch.FloatTensor(output_dim)\n",
        "\n",
        "    # You should override 'forward' method to implement detail.\n",
        "    # The input arguments and outputs can be designed as you wish.\n",
        "    def forward(self, x):\n",
        "        # |x| = (batch_size, input_dim)\n",
        "        y = torch.matmul(x, self.W) + self.b\n",
        "        # |y| = (batch_size, input_dim) * (input_dim, output_dim)\n",
        "        #     = (batch_size, output_dim)\n",
        "        \n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ny2X3a-dVzNY"
      },
      "outputs": [],
      "source": [
        "linear = MyLinear(3, 2)\n",
        "\n",
        "y = linear(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYX3K-SEVzNY",
        "outputId": "c6d74977-6bf1-4c7c-a92c-086d07f94d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 2])\n"
          ]
        }
      ],
      "source": [
        "print(y.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WXyWt-5PVzNY"
      },
      "outputs": [],
      "source": [
        "for p in linear.parameters():\n",
        "    print(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIl2ceAYVzNZ"
      },
      "source": [
        "You can see that there is no weight parameters to learn.\n",
        "Above way can forward(or calculate) values, but it cannot be trained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nug9w9sYVzNZ"
      },
      "source": [
        "### Correct way: nn.Parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FUNqHTrKVzNZ"
      },
      "outputs": [],
      "source": [
        "class MyLinear(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim=3, output_dim=2):\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.W = nn.Parameter(torch.FloatTensor(input_dim, output_dim))\n",
        "        self.b = nn.Parameter(torch.FloatTensor(output_dim))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # |x| = (batch_size, input_dim)\n",
        "        y = torch.matmul(x, self.W) + self.b\n",
        "        # |y| = (batch_size, input_dim) * (input_dim, output_dim)\n",
        "        #     = (batch_size, output_dim)\n",
        "        \n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE6wa-xxVzNZ"
      },
      "source": [
        "Reference: https://pytorch.org/docs/stable/nn.html#torch.nn.Parameter\n",
        "\n",
        "A kind of Tensor that is to be considered a module parameter.\n",
        "\n",
        "Parameters are Tensor subclasses, that have a very special property when used with Module s - when they’re assigned as Module attributes they are automatically added to the list of its parameters, and will appear e.g. in parameters() iterator. Assigning a Tensor doesn’t have such effect. This is because one might want to cache some temporary state, like last hidden state of the RNN, in the model. If there was no such class as Parameter, these temporaries would get registered too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OcC5WbacVzNa"
      },
      "outputs": [],
      "source": [
        "linear = MyLinear(3, 2)\n",
        "\n",
        "y = linear(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh81abbQVzNa",
        "outputId": "3ac6ce48-ed01-4646-c95d-88dc999d99ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 2])\n"
          ]
        }
      ],
      "source": [
        "print(y.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNx1PcfeVzNa",
        "outputId": "612074b3-2fdc-4ee5-99b9-ff1c4edf9644"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[6.9953e-34, 0.0000e+00],\n",
            "        [3.3631e-44, 0.0000e+00],\n",
            "        [       nan, 3.8000e+01]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([6.9954e-34, 0.0000e+00], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for p in linear.parameters():\n",
        "    print(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47cime2xVzNa"
      },
      "source": [
        "## nn.Linear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5Tpjuep9VzNb"
      },
      "outputs": [],
      "source": [
        "linear = nn.Linear(3, 2)\n",
        "\n",
        "y = linear(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMqR4l2kVzNb",
        "outputId": "081ccf41-854e-4215-9ec2-ae3f070a4ade"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 2])\n"
          ]
        }
      ],
      "source": [
        "print(y.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovtHNPfRVzNb",
        "outputId": "2f013623-8872-458b-fb12-a36c0743d2aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.4963,  0.5140, -0.3482],\n",
            "        [-0.3974, -0.1478,  0.5235]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0932, -0.0370], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for p in linear.parameters():\n",
        "    print(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdwHKSyhVzNb"
      },
      "source": [
        "### nn.Module can contain other nn.Module's child classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "e1UOxA36VzNb"
      },
      "outputs": [],
      "source": [
        "class MyLinear(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim=3, output_dim=2):\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # |x| = (batch_size, input_dim)\n",
        "        y = self.linear(x)\n",
        "        # |y| = (batch_size, output_dim)\n",
        "        \n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wJgIm0SlVzNb"
      },
      "outputs": [],
      "source": [
        "linear = MyLinear(3, 2)\n",
        "\n",
        "y = linear(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGdj4rkBVzNc",
        "outputId": "50c16c3c-73e9-4f45-dc9b-1dd13ded4af3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 2])\n"
          ]
        }
      ],
      "source": [
        "print(y.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDOmGSt2VzNc",
        "outputId": "5cbdf87b-0d08-464d-a728-5053a407d368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3292, -0.3696,  0.3060],\n",
            "        [ 0.5384, -0.1197,  0.0278]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0955, -0.1110], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for p in linear.parameters():\n",
        "    print(p)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}